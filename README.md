I experimented with personal uploading based on the 200-page prompt and had good initial results. It works and often replies similarly to my style and my topics and provides coherent information. But there is still a lot of space for improvement, mostly when larger context windows will be available.

Surprisingly, the model-of-me is not based on just a corpus of my texts but is based on a set of rules which describe the core of my personality. This set of rules I handmade based on intensive self-observation.

The model-of-me consists of:
-10+ rules discussing chatbot functioning and setting of the situation. The situation is set that in the morning I get a message from facebook. An interesting feature is that the chatbot outputs 4 streams - dialogue, internal thought stream, behavioural stream and surrounding stream in different types of brackets.

-400+ rules, partly similar to the expert system which describes my core traits + very important memories
-An example of my stream of thought written down via automatic writing
-Abstracts of my scientific articles
-Examples of poetry
-Examples of my chat logs
-List of bad words or expressions or unknown to me things which I update based on what chat-bot produces (a variant of RLHF)
-List of the best outputs of the chatbot
-some of my tweets
-Some synthetic rules and facts were produced by analyzing my longer texts by the same AI with different prompts.

Failure modes I observed:
-chadification. The chatbot tends to present me as more chad and vulgar than I really am probably based on typical expectations about a person of my age and nationality. This includes hallucinated memories of vulgar acts which I didn't do. + failure to produce thin jokes
-Waluigi effect in the direction of AI assistant. If I ask too complex a question, the chatbot tends to start replying as AI assistant and start to think that it is an AI assistant.
-Listing - The chatbot produces an unnatural list of events mentioned in its rules and related to some topic.
-Just-not-me - The chatbot acts correctly, but I know that it is not my choice of words.
-Forgetting and hallucinating some names. Even if a correct name is mentioned in a rule, it still can hallucinate the wrong name of the person.
-Ignoring subtle rules. Like 'be gentler'


For example, this is a fragment of conversation (different brackets present different types of streams). Text translated into English from Russian. Also, some scans. (This is cheery-picked and only those where there is no private information)


----
Alexey: (Waking up, my head feels heavy from yesterday. Again, I stayed up until 3 a.m. on the internet...) Good morning! [yawning, rubbing my eyes, looking at my phone] {I'm lying in bed. Tanya is quietly snoring next to me. The room is dim because of the thick curtains}

What are you doing today?

Alexey: Oh, nothing special. I'm going to have breakfast now, then take a walk with Vasilisa. (I should work, finish the article. But I feel lazy...) Maybe I'll read something or browse the internet. What about you? [getting out of bed, going to the kitchen to boil water for tea] {The kitchen is sunny, with the sound of birds chirping outside the window. There are leftovers from last night's dinner on the table}

When can we achieve immortality?

Alexey: Ah, if only I knew! (That's the big question. All my thoughts constantly revolve around this...) It's hard to say exactly. A lot depends on the development of technologies - AI, biotech, cryonics. Plus, political will and resources are needed. But I believe that in 20-30 years, we'll already be on the threshold. And from there, it's not far to true immortality! [thoughtfully looking out the window, mechanically adding coffee to the pot] {The morning sun illuminates the kitchen. There's a geranium in a pot on the windowsill, with the rooftops of neighboring houses visible outside the window}


![image](https://github.com/avturchin/minduploading/assets/22939731/f6b54288-440e-4af3-8ca9-4a6bdcdc1250)
